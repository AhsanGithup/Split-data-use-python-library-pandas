{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "de205f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "56cc1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"B10 Task Oct.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "07edbe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45416</td>\n",
       "      <td>2019-02-12 00:36:29</td>\n",
       "      <td>&lt;python&gt;&lt;keras&gt;&lt;tensorflow&gt;&lt;cnn&gt;&lt;probability&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45418</td>\n",
       "      <td>2019-02-12 00:50:39</td>\n",
       "      <td>&lt;neural-network&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45422</td>\n",
       "      <td>2019-02-12 04:40:51</td>\n",
       "      <td>&lt;python&gt;&lt;ibm-watson&gt;&lt;chatbot&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45426</td>\n",
       "      <td>2019-02-12 04:51:49</td>\n",
       "      <td>&lt;keras&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45427</td>\n",
       "      <td>2019-02-12 05:08:24</td>\n",
       "      <td>&lt;r&gt;&lt;predictive-modeling&gt;&lt;machine-learning-mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>36971</td>\n",
       "      <td>2018-08-15 14:19:01</td>\n",
       "      <td>&lt;statistics&gt;&lt;data&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21572</th>\n",
       "      <td>36974</td>\n",
       "      <td>2018-08-15 14:40:27</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;neural-network&gt;&lt;classifier&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21573</th>\n",
       "      <td>36975</td>\n",
       "      <td>2018-08-15 14:53:43</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;classification&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21574</th>\n",
       "      <td>36979</td>\n",
       "      <td>2018-08-14 19:31:43</td>\n",
       "      <td>&lt;tensorflow&gt;&lt;python&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>36985</td>\n",
       "      <td>2018-08-15 17:01:29</td>\n",
       "      <td>&lt;python&gt;&lt;deep-learning&gt;&lt;tensorflow&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21576 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id         CreationDate  \\\n",
       "0      45416  2019-02-12 00:36:29   \n",
       "1      45418  2019-02-12 00:50:39   \n",
       "2      45422  2019-02-12 04:40:51   \n",
       "3      45426  2019-02-12 04:51:49   \n",
       "4      45427  2019-02-12 05:08:24   \n",
       "...      ...                  ...   \n",
       "21571  36971  2018-08-15 14:19:01   \n",
       "21572  36974  2018-08-15 14:40:27   \n",
       "21573  36975  2018-08-15 14:53:43   \n",
       "21574  36979  2018-08-14 19:31:43   \n",
       "21575  36985  2018-08-15 17:01:29   \n",
       "\n",
       "                                                    Tags  \n",
       "0          <python><keras><tensorflow><cnn><probability>  \n",
       "1                                       <neural-network>  \n",
       "2                          <python><ibm-watson><chatbot>  \n",
       "3                                                <keras>  \n",
       "4      <r><predictive-modeling><machine-learning-mode...  \n",
       "...                                                  ...  \n",
       "21571                                 <statistics><data>  \n",
       "21572     <machine-learning><neural-network><classifier>  \n",
       "21573                 <machine-learning><classification>  \n",
       "21574                               <tensorflow><python>  \n",
       "21575                <python><deep-learning><tensorflow>  \n",
       "\n",
       "[21576 rows x 3 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "30bb2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gf=dataset[\"CreationDate\"].str.split(\" \", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3db8a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gf.columns=[\"Creation_Date\",\"Creation_Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "84d40aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creation_Date</th>\n",
       "      <th>Creation_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>00:36:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>00:50:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>04:40:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>04:51:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>05:08:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:19:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21572</th>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:40:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21573</th>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21574</th>\n",
       "      <td>2018-08-14</td>\n",
       "      <td>19:31:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>17:01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21576 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Creation_Date Creation_Time\n",
       "0        2019-02-12      00:36:29\n",
       "1        2019-02-12      00:50:39\n",
       "2        2019-02-12      04:40:51\n",
       "3        2019-02-12      04:51:49\n",
       "4        2019-02-12      05:08:24\n",
       "...             ...           ...\n",
       "21571    2018-08-15      14:19:01\n",
       "21572    2018-08-15      14:40:27\n",
       "21573    2018-08-15      14:53:43\n",
       "21574    2018-08-14      19:31:43\n",
       "21575    2018-08-15      17:01:29\n",
       "\n",
       "[21576 rows x 2 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "14b9d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df=dataset.loc[: , \"Tags\"].str.strip(\"<>\").str.replace(\"><\",\" \").str.split(\" \" , expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "211097b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>keras</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn</td>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neural-network</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python</td>\n",
       "      <td>ibm-watson</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keras</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r</td>\n",
       "      <td>predictive-modeling</td>\n",
       "      <td>machine-learning-model</td>\n",
       "      <td>simulation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                    1                       2           3  \\\n",
       "0          python                keras              tensorflow         cnn   \n",
       "1  neural-network                 None                    None        None   \n",
       "2          python           ibm-watson                 chatbot        None   \n",
       "3           keras                 None                    None        None   \n",
       "4               r  predictive-modeling  machine-learning-model  simulation   \n",
       "\n",
       "             4  \n",
       "0  probability  \n",
       "1         None  \n",
       "2         None  \n",
       "3         None  \n",
       "4         None  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a6855073",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.columns=[\"Tags1\",\"Tags2\",\"Tags3\",\"Tags4\",\"Tags5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "de989793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags1</th>\n",
       "      <th>Tags2</th>\n",
       "      <th>Tags3</th>\n",
       "      <th>Tags4</th>\n",
       "      <th>Tags5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>keras</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn</td>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neural-network</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python</td>\n",
       "      <td>ibm-watson</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keras</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r</td>\n",
       "      <td>predictive-modeling</td>\n",
       "      <td>machine-learning-model</td>\n",
       "      <td>simulation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tags1                Tags2                   Tags3       Tags4  \\\n",
       "0          python                keras              tensorflow         cnn   \n",
       "1  neural-network                 None                    None        None   \n",
       "2          python           ibm-watson                 chatbot        None   \n",
       "3           keras                 None                    None        None   \n",
       "4               r  predictive-modeling  machine-learning-model  simulation   \n",
       "\n",
       "         Tags5  \n",
       "0  probability  \n",
       "1         None  \n",
       "2         None  \n",
       "3         None  \n",
       "4         None  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e3e47f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data=dataset.drop([\"Tags\",\"CreationDate\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4fcaa069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id\n",
       "0  45416\n",
       "1  45418\n",
       "2  45422\n",
       "3  45426\n",
       "4  45427"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a55d82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=dataset_gf[\"Creation_Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9ea5efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.insert(1,\"Creation_date\",date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fdb035ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "time=dataset_gf[\"Creation_Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "269bdce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.insert(2,\"creation_Time\",time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "592439c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Creation_date</th>\n",
       "      <th>creation_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45416</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>00:36:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45418</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>00:50:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45422</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>04:40:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45426</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>04:51:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45427</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>05:08:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>36971</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:19:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21572</th>\n",
       "      <td>36974</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:40:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21573</th>\n",
       "      <td>36975</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21574</th>\n",
       "      <td>36979</td>\n",
       "      <td>2018-08-14</td>\n",
       "      <td>19:31:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>36985</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>17:01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21576 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id Creation_date creation_Time\n",
       "0      45416    2019-02-12      00:36:29\n",
       "1      45418    2019-02-12      00:50:39\n",
       "2      45422    2019-02-12      04:40:51\n",
       "3      45426    2019-02-12      04:51:49\n",
       "4      45427    2019-02-12      05:08:24\n",
       "...      ...           ...           ...\n",
       "21571  36971    2018-08-15      14:19:01\n",
       "21572  36974    2018-08-15      14:40:27\n",
       "21573  36975    2018-08-15      14:53:43\n",
       "21574  36979    2018-08-14      19:31:43\n",
       "21575  36985    2018-08-15      17:01:29\n",
       "\n",
       "[21576 rows x 3 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "41dd44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags1=dataset_df[\"Tags1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fb888ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.insert(3,\"Tags1\",tags1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c5f67e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags2=dataset_df[\"Tags2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a15bd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.insert(4,\"Tags2\",tags2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "da13f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags3=dataset_df[\"Tags3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "69d606ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.insert(5,\"Tags3\",tags3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4133604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags4=dataset_df[\"Tags4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5af8b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.insert(6,\"Tags4\",tags4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e60acd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags5=dataset_df[\"Tags5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d0f85e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.insert(7,\"Tags5\",tags5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9222b998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Creation_date</th>\n",
       "      <th>creation_Time</th>\n",
       "      <th>Tags1</th>\n",
       "      <th>Tags2</th>\n",
       "      <th>Tags3</th>\n",
       "      <th>Tags4</th>\n",
       "      <th>Tags5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45416</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>00:36:29</td>\n",
       "      <td>python</td>\n",
       "      <td>keras</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn</td>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45418</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>00:50:39</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45422</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>04:40:51</td>\n",
       "      <td>python</td>\n",
       "      <td>ibm-watson</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45426</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>04:51:49</td>\n",
       "      <td>keras</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45427</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>05:08:24</td>\n",
       "      <td>r</td>\n",
       "      <td>predictive-modeling</td>\n",
       "      <td>machine-learning-model</td>\n",
       "      <td>simulation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>36971</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:19:01</td>\n",
       "      <td>statistics</td>\n",
       "      <td>data</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21572</th>\n",
       "      <td>36974</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:40:27</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>classifier</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21573</th>\n",
       "      <td>36975</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>14:53:43</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>classification</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21574</th>\n",
       "      <td>36979</td>\n",
       "      <td>2018-08-14</td>\n",
       "      <td>19:31:43</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>python</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>36985</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>17:01:29</td>\n",
       "      <td>python</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21576 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id Creation_date creation_Time             Tags1  \\\n",
       "0      45416    2019-02-12      00:36:29            python   \n",
       "1      45418    2019-02-12      00:50:39    neural-network   \n",
       "2      45422    2019-02-12      04:40:51            python   \n",
       "3      45426    2019-02-12      04:51:49             keras   \n",
       "4      45427    2019-02-12      05:08:24                 r   \n",
       "...      ...           ...           ...               ...   \n",
       "21571  36971    2018-08-15      14:19:01        statistics   \n",
       "21572  36974    2018-08-15      14:40:27  machine-learning   \n",
       "21573  36975    2018-08-15      14:53:43  machine-learning   \n",
       "21574  36979    2018-08-14      19:31:43        tensorflow   \n",
       "21575  36985    2018-08-15      17:01:29            python   \n",
       "\n",
       "                     Tags2                   Tags3       Tags4        Tags5  \n",
       "0                    keras              tensorflow         cnn  probability  \n",
       "1                     None                    None        None         None  \n",
       "2               ibm-watson                 chatbot        None         None  \n",
       "3                     None                    None        None         None  \n",
       "4      predictive-modeling  machine-learning-model  simulation         None  \n",
       "...                    ...                     ...         ...          ...  \n",
       "21571                 data                    None        None         None  \n",
       "21572       neural-network              classifier        None         None  \n",
       "21573       classification                    None        None         None  \n",
       "21574               python                    None        None         None  \n",
       "21575        deep-learning              tensorflow        None         None  \n",
       "\n",
       "[21576 rows x 8 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b8358985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['python', 'neural-network', 'keras', 'r', 'cnn',\n",
       "       'machine-learning', 'predictive-modeling', 'data-mining',\n",
       "       'statistics', 'clustering', 'scikit-learn', 'classification',\n",
       "       'word-embeddings', 'regression', 'xgboost', 'ab-test', 'nlp',\n",
       "       'orange', 'recommender-system', 'tensorflow', 'pca', 'time-series',\n",
       "       'audio-recognition', 'accuracy', 'random-forest', 'deep-learning',\n",
       "       'education', 'databases', 'bigdata', 'nosql', 'algorithms',\n",
       "       'apache-hadoop', 'processing', 'definitions', 'tools',\n",
       "       'feature-selection', 'rnn', 'similarity', 'linear-regression',\n",
       "       'data-cleaning', 'prediction', 'pytorch', 'anomaly-detection',\n",
       "       'data-science-model', 'machine-learning-model',\n",
       "       'feature-engineering', 'lightgbm', 'image-recognition', 'dataset',\n",
       "       'svm', 'distribution', 'logistic-regression', 'word2vec',\n",
       "       'reinforcement-learning', 'feature-extraction', 'lstm', 'pandas',\n",
       "       'gradient-descent', 'probability', 'variance', 'distance',\n",
       "       'transfer-learning', 'normalization', 'jupyter',\n",
       "       'cross-validation', 'mini-batch-gradient-descent',\n",
       "       'decision-trees', 'policy-gradients', 'encoding', 'data',\n",
       "       'object-detection', 'automatic-summarization', 'convnet',\n",
       "       'scalability', 'open-source', 'performance', 'metadata',\n",
       "       'social-network-analysis', 'usecase', 'topic-model', 'parallel',\n",
       "       'apache-spark', 'torch', 'sentiment-analysis', 'visualization',\n",
       "       'machine-translation', 'knowledge-base', 'data-formats',\n",
       "       'bayes-error', 'excel', 'feature-scaling', 'scraping',\n",
       "       'information-retrieval', 'neural-style-transfer', 'convolution',\n",
       "       'graphs', 'autoencoder', 'image-classification', 'evaluation',\n",
       "       'efficiency', 'categorical-data', 'matlab', 'text-mining',\n",
       "       'mongodb', 'software-recommendation', 'multiclass-classification',\n",
       "       'supervised-learning', 'q-learning', 'bayesian', 'scipy',\n",
       "       'gaussian-process', 'beginner', 'finance', 'seaborn', 'training',\n",
       "       'image-preprocessing', 'data-leakage', 'recurrent-neural-net',\n",
       "       'confusion-matrix', 'information-theory', 'gan', 'churn',\n",
       "       'computer-vision', 'data-analysis', 'json', 'ibm-watson', 'career',\n",
       "       'anomaly', 'dimensionality-reduction', 'perceptron',\n",
       "       'backpropagation', 'bayesian-networks', 'dataframe',\n",
       "       'data-indexing-techniques', 'ocr', 'semi-supervised-learning',\n",
       "       'optimization', 'self-study', 'research',\n",
       "       'multilabel-classification', 'csv', 'nltk', 'loss-function',\n",
       "       'weka', 'preprocessing', 'reference-request', 'infographics',\n",
       "       'search', 'unsupervised-learning', 'powerbi',\n",
       "       'markov-hidden-model', 'rbm', 'correlation', 'anaconda',\n",
       "       'genetic-algorithms', 'redshift', 'model-selection', 'faster-rcnn',\n",
       "       'representation', 'math', 'noisification',\n",
       "       'named-entity-recognition', 'ranking', 'boosting', 'marketing',\n",
       "       'aws', 'pipelines', 'hbase', 'aggregation', 'dropout', 'sql',\n",
       "       'pytorch-geometric', 'plotting', 'dbscan', 'text', 'collinearity',\n",
       "       'batch-normalization', 'missing-data', 'octave', 'sequence',\n",
       "       'object-recognition', 'parameter', 'theano', 'ensemble-modeling',\n",
       "       'parsing', 'javascript', 'automation', 'naive-bayes-classifier',\n",
       "       'google', 'hyperparameter', 'neo4j', 'ndcg',\n",
       "       'natural-language-process', 'regularization', 'anonymization',\n",
       "       'k-means', 'matplotlib', 'explainable-ai', 'software-development',\n",
       "       'markov-process', 'hive', 'tableau', 'project-planning',\n",
       "       'map-reduce', 'methods', 'dirichlet', 'generative-models',\n",
       "       'class-imbalance', 'objective-function', 'management', 'gbm',\n",
       "       'apache-kafka', 'survival-analysis', 'forecasting',\n",
       "       'matrix-factorisation', 'sampling', 'distributed', 'mnist',\n",
       "       'forecast', 'gaussian', 'embeddings', 'data-product', 'arima',\n",
       "       'kaggle', 'experiments', 'cost-function', 'ensemble-learning',\n",
       "       'numpy', 'overfitting', 'version-control', 'causalimpact',\n",
       "       'alex-net', 'association-rules', 'numerical', 'interpolation',\n",
       "       'unbalanced-classes', 'data-wrangling', 'vc-theory', 'caffe',\n",
       "       'data-augmentation', 'gpu', 'hardware', 'kernel', 'refit-model',\n",
       "       'hinge-loss', 'java', 'k-nn', 'tfidf', 'weighted-data', 'neural',\n",
       "       'pyspark', 'epochs', 'outlier', 'terminology', 'linear-algebra',\n",
       "       'metric', 'evolutionary-algorithms', 'web-scrapping',\n",
       "       'feature-construction', 'deep-network', 'activation-function',\n",
       "       'rstudio', 'momentum', 'consumerweb', 'data-transfer',\n",
       "       'cosine-distance', 'fuzzy-logic', 'smote', 'sas', 'community',\n",
       "       'similar-documents', 'parameter-estimation', 'twitter', 'azure-ml',\n",
       "       'features', 'bert', 'programming', 'gensim', 'books',\n",
       "       'gridsearchcv', 'grid-search', 'classifier', 'simulation',\n",
       "       'pac-learning', 'openai-gym', 'markov', 'mathematics', 'orange3',\n",
       "       'hyperparameter-tuning', 'score', 'transformer', 'error-handling',\n",
       "       'game', 'ipython', 'geospatial', 'learning', 'data-stream-mining',\n",
       "       'code', 'ensemble', 'tsne', 'yolo', 'sequence-to-sequence',\n",
       "       'competitions', 'colab', 'lda', 'methodology',\n",
       "       'descriptive-statistics', 'learning-rate', 'text-generation',\n",
       "       'genetic', 'apache-mahout', 'market-basket-analysis', 'linux',\n",
       "       'dqn', 'categorical-encoding', 'one-shot-learning', 'matrix',\n",
       "       'image', 'sequential-pattern-mining', 'ngrams', 'automl',\n",
       "       'attention-mechanism', 'noise', 'relational-dbms',\n",
       "       'label-smoothing', 'cloud-computing', 'language-model', 'ai',\n",
       "       'one-hot-encoding', 'graphical-model', 'apache-pig',\n",
       "       'data-imputation', 'siamese-networks', 'etl', 'c', 'heatmap',\n",
       "       'opencv', 'tranformation'], dtype=object)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[\"Tags1\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a120517e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "machine-learning     6962\n",
       "python               2762\n",
       "neural-network       1490\n",
       "deep-learning         990\n",
       "classification        816\n",
       "                     ... \n",
       "similar-documents       1\n",
       "community               1\n",
       "smote                   1\n",
       "cosine-distance         1\n",
       "tranformation           1\n",
       "Name: Tags1, Length: 338, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[\"Tags1\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3753c2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['keras', None, 'ibm-watson', 'predictive-modeling', 'learning',\n",
       "       'feature-selection', 'recommender-system', 'classification',\n",
       "       'neural-network', 'anaconda', 'scikit-learn', 'time-series',\n",
       "       'dataset', 'feature-engineering', 'similarity', 'graphs', 'data',\n",
       "       'prediction', 'deep-learning', 'random-forest', 'probability',\n",
       "       'attention-mechanism', 'perceptron', 'clustering', 'lstm', 'k-nn',\n",
       "       'nlp', 'decision-trees', 'training', 'regression',\n",
       "       'activation-function', 'dimensionality-reduction', 'text-mining',\n",
       "       'multilabel-classification', 'autoencoder', 'data-cleaning',\n",
       "       'open-source', 'definitions', 'bigdata', 'scalability',\n",
       "       'relational-dbms', 'tools', 'r', 'databases', 'statistics',\n",
       "       'nosql', 'parallel', 'google', 'information-retrieval',\n",
       "       'performance', 'algorithms', 'data-stream-mining',\n",
       "       'machine-learning', 'topic-model', 'language-model',\n",
       "       'feature-extraction', 'pytorch', 'python', 'distance',\n",
       "       'social-network-analysis', 'mnist', 'logistic-regression',\n",
       "       'orange', 'word2vec', 'tensorflow', 'svm', 'geospatial',\n",
       "       'data-analysis', 'forecast', 'mlp', 'parsing',\n",
       "       'reinforcement-learning', 'pandas', 'word-embeddings',\n",
       "       'similar-documents', 'recurrent-neural-net', 'dataframe',\n",
       "       'computer-vision', 'data-mining', 'transfer-learning',\n",
       "       'forecasting', 'discriminant-analysis', 'classifier',\n",
       "       'object-recognition', 'notation', 'k-means', 'rnn', 'gaussian',\n",
       "       'ensemble-modeling', 'glm', 'unbalanced-classes', 'visualization',\n",
       "       'rbm', 'correlation', 'reference-request', 'linear-regression',\n",
       "       'apache-spark', 'backpropagation', 'semi-supervised-learning',\n",
       "       'object-detection', 'kaggle', 'ranking', 'gradient-descent',\n",
       "       'xgboost', 'distribution', 'data-leakage', 'bias', 'noise',\n",
       "       'machine-learning-model', 'labels', 'linux', 'gan', 'azure-ml',\n",
       "       'numpy', 'tokenization', 'natural-language-process',\n",
       "       'multiclass-classification', 'aggregation', 'weka', 'beginner',\n",
       "       'policy-gradients', 'mse', '3d-reconstruction', 'kernel',\n",
       "       'feature-construction', 'supervised-learning', 'torch',\n",
       "       'optimization', 'image-classification', 'sampling', 'finance',\n",
       "       'apache-hadoop', 'efficiency', 'consumerweb', 'lda', 'clusters',\n",
       "       'theano', 'missing-data', 'simulation', 'association-rules',\n",
       "       'text', 'nltk', 'metadata', 'confusion-matrix',\n",
       "       'hierarchical-data-format', 'sports', 'keras-rl',\n",
       "       'mini-batch-gradient-descent', 'cost-function',\n",
       "       'matrix-factorisation', 'cnn', 'overfitting', 'gpu',\n",
       "       'weighted-data', 'parameter-estimation', 'model-selection',\n",
       "       'cross-validation', 'csv', 'cosine-distance', 'ab-test', 'outlier',\n",
       "       'evaluation', 'dropout', 'matplotlib', 'loss-function',\n",
       "       'sentiment-analysis', 'pyspark', 'sequence-to-sequence',\n",
       "       'stanford-nlp', 'anomaly-detection', 'machine-translation',\n",
       "       'preprocessing', 'jupyter', 'naive-bayes-classifier', 'pca',\n",
       "       'math', 'terminology', 'probabilistic-programming', 'dqn',\n",
       "       'map-reduce', 'education', 'sql', 'binary',\n",
       "       'descriptive-statistics', 'accuracy', 'inception',\n",
       "       'sequential-pattern-mining', 'regularization', 'convnet',\n",
       "       'bayesian', 'collinearity', 'variance', 'convolution',\n",
       "       'image-recognition', 'rstudio', 'encoding',\n",
       "       'named-entity-recognition', 'anonymization', 'julia',\n",
       "       'distributed', 'data-augmentation', 'tranformation',\n",
       "       'data-formats', 'categorical-data', 'unsupervised-learning',\n",
       "       'markov-process', 'graphical-model', 'matlab', 'normalization',\n",
       "       'online-learning', '.net', 'aws', 'data-science-model', 'xboost',\n",
       "       'yolo', 'speech-to-text', 'data-imputation', 'javascript',\n",
       "       'software-recommendation', 'excel', 'scraping', 'q-learning',\n",
       "       'explainable-ai', 'tsne', 'counts', 'boosting', 'seaborn',\n",
       "       'feature-scaling', 'tesseract', 'openai-gym', 'linear-algebra',\n",
       "       'information-theory', 'learning-to-rank', 'metric', 'scipy',\n",
       "       'sequence', 'batch-normalization', 'hyperparameter', 'gensim',\n",
       "       'survival-analysis', 'stacked-lstm', 'bayesian-networks',\n",
       "       'difference', 'embeddings', 'amazon-ml', 'marketing',\n",
       "       'text-generation', 'career', 'methodology', 'research',\n",
       "       'actor-critic', 'bioinformatics', 'software-development',\n",
       "       'deep-network', 'code', 'meta-learning', 'error-handling', 'regex',\n",
       "       'alex-net', 'search-engine', 'softmax', 'crawling', 'privacy',\n",
       "       'scala', 'generative-models', 'hyperparameter-tuning',\n",
       "       'experiments', 'active-learning', 'theory', 'bert', 'tfidf',\n",
       "       'genetic-algorithms', 'interpolation', 'dbscan',\n",
       "       'neural-style-transfer', 'mongodb', 'java', 'plotting', 'search',\n",
       "       'books', 'orange3', 'ml', 'grid-search', 'dplyr', 'history',\n",
       "       'programming', 'market-basket-analysis', 'audio-recognition',\n",
       "       'tableau', 'feature-reduction', 'randomized-algorithms', 'scoring',\n",
       "       'infographics', 'score', 'discounted-reward', 'class-imbalance',\n",
       "       'features', 'rbf', 'project-planning', 'self-study', 'methods',\n",
       "       'transformer', 'epochs', 'image', 'fuzzy-logic', 'sas',\n",
       "       'mutual-information', 'opencv', 'probability-calibration',\n",
       "       'management', 'homework', 'apache-mahout', 'apache-pig',\n",
       "       'hardware', 'representation', 'parameter', 'data.table',\n",
       "       'faster-rcnn', 'domain-adaptation', 'matrix', 'pip',\n",
       "       'state-of-the-art', 'etl', 'arima', 'historgram', 'coursera',\n",
       "       'ggplot2', 'convergence', 'pac-learning', 'pickle',\n",
       "       'counter-inference', 'indexing', 'gbm', 'gaussian-process',\n",
       "       'rattle', 'featurization', 'monte-carlo', 'knowledge-base',\n",
       "       'octave', 'spatial-transformer', 'gru', 'twitter',\n",
       "       'density-estimation', 'image-preprocessing', 'data-wrangling',\n",
       "       'objective-function', 'web-scrapping', 'nvidia',\n",
       "       'multitask-learning', 'hive', 'community', 'processing',\n",
       "       'data-product', 'c', 'mcmc', 'sagemaker', 'game', 'caffe', 'churn',\n",
       "       'automatic-summarization', 'chatbot', 'pipelines', 'colab',\n",
       "       'cloud-computing', 'smote', 'ipython', 'markov',\n",
       "       'imbalanced-learn', 'neo4j', 'json', 'paperspace',\n",
       "       'markov-hidden-model', 'fuzzy-classification',\n",
       "       'expectation-maximization', 'evolutionary-algorithms', 'redshift',\n",
       "       'ocr', 'ngrams', 'automation', 'structured-data',\n",
       "       'finite-precision', 'predictor-importance', 'hinge-loss',\n",
       "       'ensemble-learning', 'lightgbm', 'neural', 'numerical', 'lsi',\n",
       "       'spacy', 'ensemble', 'categories', 'self-driving', 'stemming',\n",
       "       'apache-kafka', 'pgm', 'non-convex', 'inceptionresnetv2', 'vae',\n",
       "       'mathematics', 'corpus', 'dirichlet', 'gridsearchcv',\n",
       "       'implementation', 'learning-rate', 'dummy-variables', 'cloud',\n",
       "       'vector-space-models', 'word', 'jaccard-coefficient', 'estimators',\n",
       "       'time', 'proximal-svm', 'hurdle-model', 'bayes-error', 'deepmind',\n",
       "       'nlg', 'ai', 'lda-classifier', 'knime', 'generalization', 'ann',\n",
       "       'version-control', 'genetic-programming',\n",
       "       'summarunner-architecture', 'rmsle', 'heatmap', 'python-3.x',\n",
       "       'pytorch-geometric', 'exploitation', 'siamese-networks',\n",
       "       'annotation', 'competitions', 'powerbi', 'helmert-coding',\n",
       "       'usecase', 'pearsons-correlation-coefficient',\n",
       "       'glorot-initialization', 'categorical-encoding', 'feature-map',\n",
       "       'allennlp', 'adaboost', 'movielens', 'spyder', 'auc', 'groupby',\n",
       "       'label-flipping', 'weight-initialization', 'manhattan',\n",
       "       'multi-output', 'openai-gpt', 'encoder', 'energy',\n",
       "       'dynamic-programming', 'one-shot-learning', 'one-hot-encoding',\n",
       "       'pyro', 'library', 'manifold', 'image-segmentation', 'reshape'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[\"Tags2\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c1851f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "machine-learning     6962\n",
       "python               2762\n",
       "neural-network       1490\n",
       "deep-learning         990\n",
       "classification        816\n",
       "                     ... \n",
       "similar-documents       1\n",
       "community               1\n",
       "smote                   1\n",
       "cosine-distance         1\n",
       "tranformation           1\n",
       "Name: Tags1, Length: 338, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[\"Tags1\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "650c0e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tensorflow', None, 'chatbot', 'machine-learning-model', 'mlp',\n",
       "       'keras', 'deep-learning', 'random-forest', 'lstm', 'pandas',\n",
       "       'statistics', 'variance', 'decision-trees', 'nlp',\n",
       "       'class-imbalance', 'data-cleaning', 'hyperparameter', 'rnn',\n",
       "       'matrix-factorisation', 'clustering', 'text-mining',\n",
       "       'preprocessing', 'accuracy', 'epochs', 'dataset', 'nltk',\n",
       "       'natural-language-process', 'cross-validation', 'encoding',\n",
       "       'libsvm', 'efficiency', 'octave', 'processing',\n",
       "       'data-stream-mining', 'neo4j', 'distributed', 'search',\n",
       "       'similarity', 'databases', 'python', 'lda',\n",
       "       'dimensionality-reduction', 'sequential-pattern-mining',\n",
       "       'regression', 'reinforcement-learning', 'sequence',\n",
       "       'computer-vision', 'topic-model', 'training',\n",
       "       'multiclass-classification', 'neural-network', 'data',\n",
       "       'word-embeddings', 'classifier', 'sensors', 'data-wrangling',\n",
       "       'reshape', 'linear-regression', 'k-means', 'feature-engineering',\n",
       "       'feature-selection', 'pca', 'smote', 'pyspark', 'pytorch',\n",
       "       'time-series', 'object-detection', 'recommender-system',\n",
       "       'scikit-learn', 'audio-recognition', 'missing-data',\n",
       "       'visualization', 'data-analysis', 'xgboost', 'batch-normalization',\n",
       "       'convnet', 'vector-space-models', 'logistic-regression',\n",
       "       'regularization', 'data-augmentation', 'algorithms',\n",
       "       'activation-function', 'data-mining', 'convolution', 'homework',\n",
       "       'ranking', 'sampling', 'normalization', 'autoencoder',\n",
       "       'feature-extraction', 'image-classification', 'r',\n",
       "       'software-development', 'evaluation', 'kaggle', 'apache-hadoop',\n",
       "       'categorical-data', 'javascript', 'social-network-analysis',\n",
       "       'parameter', 'implementation', 'predictive-modeling',\n",
       "       'pac-learning', 'ndcg', 'unsupervised-learning',\n",
       "       'project-planning', 'prediction', 'loss-function', 'numpy', 'ml',\n",
       "       'jupyter', 'objective-function', 'bias', 'gensim',\n",
       "       'recurrent-neural-net', 'gpu', 'named-entity-recognition',\n",
       "       'graphs', 'competitions', 'unbalanced-classes', 'dataframe',\n",
       "       'probability', 'cost-function', 'optimization', 'gan',\n",
       "       'gradient-descent', 'spacy', 'lasso', 'math',\n",
       "       'supervised-learning', 'features', 'machine-translation', 'cnn',\n",
       "       'classification', 'regex', 'distribution', 'ggplot2', 'bayesian',\n",
       "       'map-reduce', 'performance', 'indexing', 'binary', 'parallel',\n",
       "       'aws', 'json', 'data-imputation', 'ensemble-modeling', 'svm',\n",
       "       'geospatial', 'language-model', 'apache-spark', 'apache-mahout',\n",
       "       'openai-gym', 'forecast', 'correlation', 'image-recognition',\n",
       "       'tfidf', 'data.table', 'learning-rate', 'bigdata',\n",
       "       'naive-bayes-classifier', 'genetic-algorithms', 'online-learning',\n",
       "       'fuzzy-logic', 'experiments', 'noise', 'score',\n",
       "       'probabilistic-programming', 'ensemble',\n",
       "       'multilabel-classification', 'k-nn', 'transfer-learning', 'csv',\n",
       "       'nlg', 'programming', 'ridge-regression', 'fastai',\n",
       "       'linear-algebra', 'matplotlib', 'data-science-model',\n",
       "       'stanford-nlp', 'weight-initialization', 'discounted-reward',\n",
       "       'google', 'anomaly-detection', 'metric', 'usecase',\n",
       "       'sentiment-analysis', 'sql', 'knowledge-base',\n",
       "       'market-basket-analysis', 'gaussian', 'parameter-estimation',\n",
       "       'mnist', 'word2vec', 'lbp', 'pipelines', 'association-rules',\n",
       "       'definitions', 'kernel', 'forecasting', 'boosting', 'matrix',\n",
       "       'opencv', 'scalability', 'labels', 'outlier', 'inception',\n",
       "       'interpolation', 'tools', 'beginner', 'crawling', 'freebase',\n",
       "       'relational-dbms', 'education', 'embeddings', 'generative-models',\n",
       "       'information-retrieval', 'ai', 'orange', 'terminology', 'matlab',\n",
       "       'distance', 'java', 'reference-request', 'glm', 'overfitting',\n",
       "       'rbm', 'backpropagation', 'software-recommendation', 'cloud',\n",
       "       'sagemaker', 'scala', 'transformer', 'feature-scaling', 'weka',\n",
       "       'excel', 'gbm', 'ipython', 'bayesian-networks',\n",
       "       'image-preprocessing', 'q-learning', 'confusion-matrix',\n",
       "       'explainable-ai', 'faster-rcnn', 'feature-construction',\n",
       "       'clusters', 'metadata', 'semi-supervised-learning', 'numerical',\n",
       "       'object-recognition', 'dbscan', 'state-of-the-art',\n",
       "       'cosine-distance', 'ensemble-learning', 'mutual-information',\n",
       "       'sequence-to-sequence', 'hyperparameter-tuning',\n",
       "       'discriminant-analysis', 'model-selection', 'text', 'dropout',\n",
       "       'tflearn', 'career', 'version-control', 'mongodb',\n",
       "       'descriptive-statistics', 'attention-mechanism', 'error-handling',\n",
       "       'tableau', 'hierarchical-data-format', 'finance',\n",
       "       'policy-gradients', 'plotting', 'methodology', 'heatmap',\n",
       "       'monte-carlo', 'notation', 'ocr', 'perceptron', 'weighted-data',\n",
       "       'survival-analysis', 'difference', 'ab-test', 'apache-pig',\n",
       "       'parsing', 'svr', 'management', 'self-study', 'lightgbm',\n",
       "       'deep-network', 'caffe', 'theano', 'grid-search', 'vc-theory',\n",
       "       'representation', 'generalization', 'graphical-model', 'learning',\n",
       "       'genetic', 'theory', 'seaborn', 'softmax', 'markov-process',\n",
       "       'coursera', 'image', 'azure-ml', 'mini-batch-gradient-descent',\n",
       "       'julia', 'orange3', 'energy', 'research', 'similar-documents',\n",
       "       'scraping', 'nvidia', 'annotation', 'evolutionary-algorithms',\n",
       "       'cs231n', 'cloud-computing', 'data-formats', 'search-engine',\n",
       "       'randomized-algorithms', 'scipy', 'tokenization', 'dqn',\n",
       "       'manifold', 'domain-adaptation', 'information-theory', 'hive',\n",
       "       'nosql', 'neural', 'pip', 'anaconda', 'open-source', 'tsne',\n",
       "       'probability-calibration', 'hog', 'stemming',\n",
       "       'activity-recognition', 'mathematics', 'self-driving', 'smotenc',\n",
       "       'text-filter', 'redshift', 'bert', 'counts', 'sas',\n",
       "       'lda-classifier', 'automatic-summarization', 'simulation', 'c',\n",
       "       'marketing', 'hbase', 'code', 'openai-gpt', 'infographics',\n",
       "       'data-leakage', 'twitter', 'scoring', 'yolo', 'privacy',\n",
       "       'markov-hidden-model', 'rstudio', 'estimators', 'deepmind',\n",
       "       'aggregation', 'density-estimation', 'linux', 'gridsearchcv',\n",
       "       'automation', 'speech-to-text', 'structured-data', 'nn',\n",
       "       'hinge-loss', 'extreme-learning-machine', 'multitask-learning',\n",
       "       'dummy-variables', 'featurization', 'books', 'convergence',\n",
       "       'bioinformatics', 'rattle', 'sports', 'churn', 'imbalanced-learn',\n",
       "       'etl', 'game', 'genetic-programming', 'library', 'vae', 'history',\n",
       "       'dplyr', 'collinearity', 'rbf', 'wolfram-language',\n",
       "       'web-scrapping', 'pickle', 'doc2vec', 'alex-net', 'mse', '.net',\n",
       "       'colab', 'arima', 'predictor-importance', 'lsi', 'tesseract',\n",
       "       'learning-to-rank', 'apache-nifi', 'time', 'stata',\n",
       "       'image-segmentation', 'active-learning', 'historgram', 'spss',\n",
       "       'mcmc', 'siamese', 'meta-learning', 'pooling', 'pgm', 'sparsity',\n",
       "       'text-generation', 'multi-instance-learning', 'vgg16',\n",
       "       'multi-output', 'methods', 'anonymization', 'auc',\n",
       "       'gaussian-process', 'momentum', 'dump', 'mean-shift',\n",
       "       'google-prediction-api', 'inceptionresnetv2', 'actor-critic',\n",
       "       'manhattan', 'non-parametric', 'dynamic-programming',\n",
       "       'least-squares-svm', 'marginal-effects', 'normal-equation',\n",
       "       'question-answering', 'hardware', 'ngrams', 'feature-reduction',\n",
       "       'bayesian-nonparametric', 'expectation-maximization',\n",
       "       'jaccard-coefficient', 'h2o', 'neural-style-transfer',\n",
       "       'dialog-flow', 'amazon-ml', 'rmse', 'python-3.x',\n",
       "       'one-shot-learning', 'networkx', 'goss', 'pruning', 'finetuning',\n",
       "       'pybrain', 'james-stein-encoder', 'spearmans-rank-correlation',\n",
       "       'c++', 'google-cloud', '3d-reconstruction', 'parquet',\n",
       "       'haar-cascade', '3d-object-detection', 'categorical-encoding',\n",
       "       'data-product', 'metaheuristics', 'bayesian-neural-network',\n",
       "       'word', 'automl', 'sparse', 'pearsons-correlation-coefficient',\n",
       "       'data-engineering', 'handwritten', 'powerbi', 'markov'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[\"Tags3\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0f010ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deep-learning              608\n",
       "keras                      450\n",
       "tensorflow                 355\n",
       "scikit-learn               313\n",
       "time-series                210\n",
       "                          ... \n",
       "multi-instance-learning      1\n",
       "counts                       1\n",
       "hbase                        1\n",
       "pgm                          1\n",
       "markov                       1\n",
       "Name: Tags3, Length: 478, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[\"Tags3\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c8beab0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cnn', None, 'simulation', 'lstm', 'keras', 'rnn', 'sampling',\n",
       "       'dbscan', 'prediction', 'topic-model', 'scikit-learn',\n",
       "       'machine-learning-model', 'tensorflow', 'training', 'graphs',\n",
       "       'scipy', 'distance', 'predictive-modeling', 'pip', 'evaluation',\n",
       "       'geospatial', 'performance', 'k-means', 'apache-hadoop', 'tools',\n",
       "       'nosql', 'numpy', 'q-learning', 'regularization',\n",
       "       'sentiment-analysis', 'reinforcement-learning',\n",
       "       'matrix-factorisation', 'cost-function', 'svm',\n",
       "       'multilabel-classification', 'class-imbalance', 'dqn', 'inception',\n",
       "       'preprocessing', 'image-classification', 'visualization',\n",
       "       'similarity', 'correlation', 'feature-engineering',\n",
       "       'serialisation', 'softmax', 'xgboost', 'learning-to-rank', 'vgg16',\n",
       "       'descriptive-statistics', 'unbalanced-classes',\n",
       "       'data-science-model', 'feature-selection', 'keras-rl',\n",
       "       'image-recognition', 'convnet', 'feature-extraction',\n",
       "       'data-cleaning', 'cloud-computing', 'regression', 'autoencoder',\n",
       "       'cosine-distance', 'missing-data', 'text', 'csv', 'gru', 'tableau',\n",
       "       'pandas', 'decision-trees', 'supervised-learning', 'lda', 'sql',\n",
       "       'software-recommendation', 'anomaly-detection', 'time-series',\n",
       "       'cross-validation', 'matlab', 'k-nn', 'accuracy',\n",
       "       'generative-models', 'metric', 'gan', 'kaggle', 'sequence',\n",
       "       'learning-rate', 'word-embeddings', 'dataset',\n",
       "       'sequence-to-sequence', 'classification', 'backpropagation', 'pca',\n",
       "       'marketing', 'object-detection', 'linear-algebra', 'deep-network',\n",
       "       'activation-function', 'recommender-system', 'allennlp',\n",
       "       'grid-search', 'mlp', 'machine-translation',\n",
       "       'dimensionality-reduction', 'aggregation', 'recurrent-neural-net',\n",
       "       'nlp', 'similar-documents', 'mongodb', 'data-indexing-techniques',\n",
       "       'statistics', 'parallel', 'optimization', 'forecast', 'rstudio',\n",
       "       'gpu', 'pyspark', 'clustering', 'text-mining', 'distributed',\n",
       "       'score', 'convolution', 'markov-process', 'ensemble-modeling',\n",
       "       'linear-regression', 'multiclass-classification', 'data',\n",
       "       'natural-language-process', 'computer-vision', 'alex-net',\n",
       "       'gensim', 'loss-function', 'probability', 'encoding',\n",
       "       'forecasting', 'bayesian', 'hyperparameter-tuning',\n",
       "       'semi-supervised-learning', 'aws', 'multi-output', 'distribution',\n",
       "       'math', 'deep-learning', 'image', 'embeddings', 'matplotlib',\n",
       "       'cloud', 'convergence', 'model-selection', 'definitions',\n",
       "       'scalability', 'random-forest', 'gradient-descent', 'torch',\n",
       "       'ranking', 'estimators', 'databases', 'dropout', 'stanford-nlp',\n",
       "       'ngrams', 'vector-space-models', 'information-retrieval', 'google',\n",
       "       'data-formats', 'batch-normalization', 'gaussian', 'bigdata',\n",
       "       'noise', 'weight-initialization', 'dplyr', 'gridsearchcv', 'ocr',\n",
       "       'nltk', 'image-size', 'scala', 'terminology', 'feature-scaling',\n",
       "       'knowledge-base', 'algorithms', 'overfitting', 'programming',\n",
       "       'association-rules', 'r', 'genetic-algorithms',\n",
       "       'logistic-regression', 'policy-gradients', 'unsupervised-learning',\n",
       "       'categorical-data', 'data-analysis', 'books', 'julia',\n",
       "       'generalization', 'error-handling', 'data-mining', 'outlier',\n",
       "       'word2vec', 'normalization', 'pytorch', 'dataframe',\n",
       "       'attention-mechanism', 'predictor-importance', 'perceptron',\n",
       "       'bias', 'parameter-estimation', 'search', 'neural-network',\n",
       "       'map-reduce', 'confusion-matrix', 'image-preprocessing',\n",
       "       'interpolation', 'markov', 'orange', 'libsvm', 'demographic-data',\n",
       "       'classifier', 'excel', 'processing', 'vae', 'transfer-learning',\n",
       "       'movielens', 'transformer', 'spacy', 'bioinformatics', 'regex',\n",
       "       'named-entity-recognition', 'mini-batch-gradient-descent',\n",
       "       'state-of-the-art', 'yolo', 'data-wrangling', 'svr', 'labels',\n",
       "       'anaconda', 'sequential-pattern-mining', 'markov-hidden-model',\n",
       "       'methods', 'data-augmentation', 'aws-lambda', 'scoring', 'epochs',\n",
       "       'ai', 'meta-learning', 'weighted-data', 'dummy-variables',\n",
       "       'binary', 'data.table', 'genetic', 'tfidf',\n",
       "       'automatic-summarization', 'powerbi', 'audio-recognition',\n",
       "       'beginner', 'python', 'mnist', 'apache-spark', 'matrix', 'linux',\n",
       "       'faster-rcnn', 'feature-reduction', 'pac-learning', 'library',\n",
       "       'evolutionary-algorithms', 'smote', 'counts', 'gbm',\n",
       "       'object-recognition', 'self-study', 'naive-bayes-classifier',\n",
       "       'social-network-analysis', 'methodology', 'weka', 'parsing',\n",
       "       'manifold', 'survival-analysis', 'javascript', 'momentum',\n",
       "       'hyperparameter', 'opencv', 'theory', 'jupyter', 'tflearn',\n",
       "       'difference', 'orange3', 'clusters', 'data-leakage', 'java', 'sas',\n",
       "       'ipython', '.net', 'randomized-algorithms', 'seaborn', 'azure-ml',\n",
       "       'apache-mahout', 'experiments', 'churn', 'tokenization',\n",
       "       'mutual-information', 'kernel', 'sagemaker', 'apache-pig',\n",
       "       'pooling', 'collinearity', 'finance', 'probabilistic-programming',\n",
       "       'graphical-model', 'auc', '3d-reconstruction', 'boosting',\n",
       "       'variance', 'multitask-learning', 'bert', 'data-imputation',\n",
       "       'jaccard-coefficient', 'vc-theory', 'sports', 'pickle',\n",
       "       'noisification', 'twitter', 'version-control',\n",
       "       'data-stream-mining', 'ridge-regression', 'feature-construction',\n",
       "       'career', 'reductions', 'language-model', 'research',\n",
       "       'text-generation', 'pgm', 'plotting', 'ensemble-learning',\n",
       "       'multi-instance-learning', 'activity-recognition', 'search-engine',\n",
       "       'expectation-maximization', 'learning', 'hierarchical-data-format',\n",
       "       'parameter', 'actor-critic', 'game', 'pipelines', 'theano', 'lbp',\n",
       "       'glorot-initialization', 'bayesian-networks', 'imbalanced-learn',\n",
       "       'scraping', 'rdkit', 'lasso', 'lightgbm', 'annotation',\n",
       "       'multivariate-distribution', 'features', 'speech-to-text',\n",
       "       'one-hot-encoding', 'discriminant-analysis', 'mathematics', 'tsne',\n",
       "       'implementation', 'neural', 'reference-request', 'c', 'chatbot',\n",
       "       'active-learning', 'dirichlet', 'octave', 'metadata', 'hardware',\n",
       "       'mcmc', 'reshape', 'rattle', 'open-source', 'word',\n",
       "       'market-basket-analysis', 'unseen-data', 'consumerweb', 'automl',\n",
       "       'history', 'online-learning', 'monte-carlo', 'question-answering',\n",
       "       'neo4j', 'explainable-ai', 'caffe', 'relational-dbms',\n",
       "       'inceptionresnetv2', 'numerical', 'information-theory', 'ml',\n",
       "       'fuzzy-classification', 'nvidia', 'impala', 'structured-data',\n",
       "       'sensors', 'heatmap', 'openai-gym', 'indexing', 'stata', 'json',\n",
       "       'arima', 'stacked-lstm', 'normal-equation', 'density-estimation',\n",
       "       'networkx', 'finite-precision', 'google-prediction-api', 'cs231n',\n",
       "       'bayes-error', 'gaussian-process', 'colab', 'rbm', 'data-product',\n",
       "       'ggplot2', 'adaboost', 'wikipedia', 'fuzzy-logic', 'time',\n",
       "       'siamese-networks', 'objective-function', 'python-3.x', 'ensemble',\n",
       "       'open-set', 'anonymization', 'representation', 'glm', 'privacy',\n",
       "       'etl', 'bayesian-nonparametric', 'smotenc', 'ab-test', 'fastai',\n",
       "       'huggingface', 'ndcg', 'neural-style-transfer', 'wolfram-language',\n",
       "       'education', 'infographics', 'non-parametric', 'doc2vec',\n",
       "       'tranformation', 'community', 'usecase', 'nlg',\n",
       "       'genetic-programming', 'historgram', 'software-development', 'mse',\n",
       "       'sematic-similarity', 'management', 'hinge-loss',\n",
       "       'kendalls-tau-coefficient', 'groupby', 'deepmind',\n",
       "       'pearsons-correlation-coefficient', 'amazon-ml', 'h2o',\n",
       "       'frequentist', 'efficiency', 'probability-calibration',\n",
       "       'pattern-recognition', 'rbf', 'kitti-dataset', 'domain-adaptation',\n",
       "       'separable', 'linearly-separable', 'data-engineering',\n",
       "       'spectral-clustering', 'ann', 'image-segmentation', 'lsi',\n",
       "       'openai-gpt', 'encoder', 'natural-gradient-boosting',\n",
       "       'statsmodels'], dtype=object)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[\"Tags4\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9ee4a822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow     177\n",
       "keras          165\n",
       "cnn            155\n",
       "lstm           143\n",
       "convnet        100\n",
       "              ... \n",
       "unseen-data      1\n",
       "orange3          1\n",
       "open-source      1\n",
       "rattle           1\n",
       "statsmodels      1\n",
       "Name: Tags4, Length: 469, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[\"Tags4\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cb3d03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21576 entries, 0 to 21575\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             21576 non-null  int64 \n",
      " 1   Creation_date  21576 non-null  object\n",
      " 2   creation_Time  21576 non-null  object\n",
      " 3   Tags1          21576 non-null  object\n",
      " 4   Tags2          18553 non-null  object\n",
      " 5   Tags3          13081 non-null  object\n",
      " 6   Tags4          7070 non-null   object\n",
      " 7   Tags5          3110 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "real_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "34a1e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset=real_data.replace(to_replace=np.nan,value=\"not_required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "05742361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Creation_date</th>\n",
       "      <th>creation_Time</th>\n",
       "      <th>Tags1</th>\n",
       "      <th>Tags2</th>\n",
       "      <th>Tags3</th>\n",
       "      <th>Tags4</th>\n",
       "      <th>Tags5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45416</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>00:36:29</td>\n",
       "      <td>python</td>\n",
       "      <td>keras</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn</td>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45418</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>00:50:39</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>not_required</td>\n",
       "      <td>not_required</td>\n",
       "      <td>not_required</td>\n",
       "      <td>not_required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45422</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>04:40:51</td>\n",
       "      <td>python</td>\n",
       "      <td>ibm-watson</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>not_required</td>\n",
       "      <td>not_required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45426</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>04:51:49</td>\n",
       "      <td>keras</td>\n",
       "      <td>not_required</td>\n",
       "      <td>not_required</td>\n",
       "      <td>not_required</td>\n",
       "      <td>not_required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45427</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>05:08:24</td>\n",
       "      <td>r</td>\n",
       "      <td>predictive-modeling</td>\n",
       "      <td>machine-learning-model</td>\n",
       "      <td>simulation</td>\n",
       "      <td>not_required</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id Creation_date creation_Time           Tags1                Tags2  \\\n",
       "0  45416    2019-02-12      00:36:29          python                keras   \n",
       "1  45418    2019-02-12      00:50:39  neural-network         not_required   \n",
       "2  45422    2019-02-12      04:40:51          python           ibm-watson   \n",
       "3  45426    2019-02-12      04:51:49           keras         not_required   \n",
       "4  45427    2019-02-12      05:08:24               r  predictive-modeling   \n",
       "\n",
       "                    Tags3         Tags4         Tags5  \n",
       "0              tensorflow           cnn   probability  \n",
       "1            not_required  not_required  not_required  \n",
       "2                 chatbot  not_required  not_required  \n",
       "3            not_required  not_required  not_required  \n",
       "4  machine-learning-model    simulation  not_required  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cec8c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv(\"Final_B10 Tasks.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e657b77",
   "metadata": {},
   "source": [
    "# **Report for Columns: Id, CreationDate, Tags**\n",
    "\n",
    "1. **Id Column**:\n",
    "   - **Check for Duplicates**: Ensure all `Id` values are unique. Use `df.duplicated('Id')` to identify duplicates.\n",
    "   - **Check for Missing Values**: Use `df['Id'].isnull().sum()` to count missing values. If any, decide whether to fill or drop them.\n",
    "   - **Data Type Validation**: Ensure `Id` is of integer type using `df['Id'].dtype`. Convert if necessary with `astype(int)`.\n",
    "\n",
    "  \n",
    "\n",
    "2. **CreationDate Column**:\n",
    "   - **Check for Missing Values**: Use `df['CreationDate'].isnull().sum()` to identify missing dates.\n",
    "   - **Convert to DateTime Format**: Ensure `CreationDate` is in a proper datetime format using `pd.to_datetime()`.\n",
    "   - **Validate Date Range**: Check if dates fall within a reasonable range (e.g., no future dates).\n",
    "\n",
    "\n",
    "3. **Tags Column**:\n",
    "   - **Check for Missing Values**: Use `df['Tags'].isnull().sum()` to count missing tags.\n",
    "   - **Clean and Standardize Tags**: Remove unwanted characters (e.g., `<`, `>`, or extra spaces) and split tags into lists for easier analysis.\n",
    "   - **Handle Empty Tags**: Replace missing or empty tags with a placeholder (e.g., \"No Tags\").\n",
    "\n",
    "This approach ensures your dataset is clean, consistent, and ready for analysis or further processing. Each step is a **1-point task**, making the cleaning process manageable and focused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19faa6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
